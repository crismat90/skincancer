{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Author: Cristina Caro González\n",
        "\n",
        "Contact: crismat02@gmail.com"
      ],
      "metadata": {
        "id": "8ed5Y-sg4xLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENHANCING AUTOMATED DETECTION AND CLASSIFICATION OF SKIN CANCER USING ADVANCED IMAGE FILTERING, FEATURE EXTRACTION, AND SYNTHETIC DATA.**"
      ],
      "metadata": {
        "id": "fy1CAW4R4-xA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDYrLeXLAUkU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G7cIG0yBArI"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29K36SyrBA0x"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgH_5rePBA29"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "np.random.seed(123)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "import itertools\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziSlNiYhEW4-"
      },
      "outputs": [],
      "source": [
        "#1. Function to plot model's validation loss and validation accuracy\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8nTD3DCE2M2"
      },
      "outputs": [],
      "source": [
        "from os import chdir # to alter your working directory\n",
        "chdir(\"/content/drive/MyDrive/TFM Cancer AI/TFM/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4OBVF4sEfC3"
      },
      "outputs": [],
      "source": [
        "base_skin_dir = os.path.join(\"/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel\")\n",
        "\n",
        "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
        "\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
        "\n",
        "# This dictionary is useful for displaying more human-friendly labels later on\n",
        "\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stq4Ry30EfFj"
      },
      "outputs": [],
      "source": [
        "skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
        "\n",
        "# Creating New Columns for better readability\n",
        "\n",
        "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n",
        "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get)\n",
        "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku49V5vLEfIL"
      },
      "outputs": [],
      "source": [
        "# Now lets see the sample of tile_df to look on newly made columns\n",
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4C3xxCYEfLJ"
      },
      "outputs": [],
      "source": [
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhH4o9YOEfOL"
      },
      "outputs": [],
      "source": [
        "skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO8xMYomEfQh"
      },
      "outputs": [],
      "source": [
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vznj6uHrEfTS"
      },
      "outputs": [],
      "source": [
        "print(skin_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OqcsqUsEW7e"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\n",
        "skin_df['cell_type'].value_counts().plot(kind='bar', ax=ax1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgn5XXtmGo37"
      },
      "source": [
        "Plotting of Technical Validation field (ground truth) which is dx_type to see the distribution of its 4 categories which are listed below :\n",
        "1. Histopathology(Histo): Histopathologic diagnoses of excised lesions have been performed by specialized dermatopathologists.\n",
        "2. Confocal: Reflectance confocal microscopy is an in-vivo imaging technique with a resolution at near-cellular level , and some facial benign with a grey-world assumption of all training-set images in Lab-color space before and after manual histogram changes.\n",
        "3. Follow-up: If nevi monitored by digital dermatoscopy did not show any changes during 3 follow-up visits or 1.5 years biologists accepted this as evidence of biologic benignity. Only nevi, but no other benign diagnoses were labeled with this type of ground-truth because dermatologists usually do not monitor dermatofibromas, seborrheic keratoses, or vascular lesions.\n",
        "4. Consensus: For typical benign cases without histopathology or followup biologists provide an expert-consensus rating of authors PT and HK. They applied the consensus label only if both authors independently gave the same unequivocal benign diagnosis. Lesions with this type of groundtruth were usually photographed for educational reasons and did not need further follow-up or biopsy for confirmation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBwMbw0HEW_v"
      },
      "outputs": [],
      "source": [
        "skin_df['dx_type'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcNZkz-2EXCA"
      },
      "outputs": [],
      "source": [
        "skin_df['localization'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YheCzRXGx6O"
      },
      "outputs": [],
      "source": [
        "skin_df['age'].hist(bins=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXTMm6KKGx80"
      },
      "outputs": [],
      "source": [
        "skin_df['sex'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twsYCqsx9Uz6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import concurrent.futures\n",
        "\n",
        "def load_resize_save(image_path, output_dir):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((100, 75), Image.ANTIALIAS) #Antialias is one of the most advanced methods for color normalization, as it calculates an average of surrounding pixels to determine the new value of each pixel.\n",
        "    output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
        "    img.save(output_path)\n",
        "    return output_path\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    skin_df['path'] = list(executor.map(load_resize_save, skin_df['path'], [output_dir]*len(skin_df)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u5cAwkCfz2W"
      },
      "outputs": [],
      "source": [
        "skin_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jYUUTY6Gx_p"
      },
      "outputs": [],
      "source": [
        "#skin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))\n",
        "\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/skin_df_resize.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjIiNBaTGyBn"
      },
      "outputs": [],
      "source": [
        "skin_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSk8nGNpGyD0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "n_samples = 5\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs, skin_df.sort_values(['cell_type']).groupby('cell_type')):\n",
        "    n_axs[0].set_title(type_name)\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
        "        img = mpimg.imread(c_row['path'])  # Cargar la imagen del disco\n",
        "        c_ax.imshow(img)\n",
        "        c_ax.axis('off')\n",
        "fig.savefig('category_samples.png', dpi=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzdwFVZuH7EK"
      },
      "source": [
        "In this code, I've replaced skin_df['image'] with skin_df['path'] and then used cv2.imread(x) to load each image from the disk before getting its shape. Remember, cv2.imread() returns a numpy array representing the image, so you can call .shape on the result to get the dimensions of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c9IQ9PkGyG2"
      },
      "outputs": [],
      "source": [
        "# Checking the image size distribution\n",
        "# skin_df['image'].map(lambda x: x.shape).value_counts()\n",
        "\n",
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "# Checking the image size distribution\n",
        "#skin_df['path'].map(lambda x: cv2.imread(x).shape).value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAcJzdu0HVXp"
      },
      "outputs": [],
      "source": [
        "#features=skin_df.drop(columns=['cell_type_idx', 'dx', 'cell_type'],axis=1)\n",
        "#target=skin_df['cell_type_idx']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heuNAKeSDD9V"
      },
      "outputs": [],
      "source": [
        "skin_df\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skin_df_withoutExtraVariables= skin_df.copy()"
      ],
      "metadata": {
        "id": "ZVoPvvBKtmT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srdR-Pa87A7C"
      },
      "outputs": [],
      "source": [
        "# We introduce an additional variable to measure the average color of the image:\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io\n",
        "\n",
        "# Define a function to calculate the average color of an image.\n",
        "def calculate_mean_color(row):\n",
        "    # Load the image\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # We calculate the average color\n",
        "    mean_colors = cv2.mean(image)[:3]\n",
        "\n",
        "    # Return the color values.\n",
        "    return mean_colors[2], mean_colors[1], mean_colors[0]\n",
        "\n",
        "# Load the dataset\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the average colors in parallel.\n",
        "results = Parallel(n_jobs=-1)(delayed(calculate_mean_color)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "mean_red, mean_green, mean_blue = zip(*results)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['mean_red'] = mean_red\n",
        "skin_df['mean_green'] = mean_green\n",
        "skin_df['mean_blue'] = mean_blue\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DizLTJo77BAv"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JTLzFtD7BEX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, feature, color\n",
        "\n",
        "def calculate_texture_features(row):\n",
        "    # Guarda el dataset actualizado\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Scale the values to a range of 0-255 and convert them to integers.\n",
        "    gray_image = (gray_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Calculate the GLCM (Gray-Level Co-occurrence Matrix).\n",
        "    glcm = feature.greycomatrix(gray_image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "\n",
        "    # Calculate the texture features.\n",
        "    contrast = feature.greycoprops(glcm, prop='contrast')\n",
        "    homogeneity = feature.greycoprops(glcm, prop='homogeneity')\n",
        "    energy = feature.greycoprops(glcm, prop='energy')\n",
        "\n",
        "    # Return the features.\n",
        "    return contrast[0, 0], homogeneity[0, 0], energy[0, 0]\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the texture features in parallel.\n",
        "results = Parallel(n_jobs=-1)(delayed(calculate_texture_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "contrast, homogeneity, energy = zip(*results)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['contrast'] = contrast\n",
        "skin_df['homogeneity'] = homogeneity\n",
        "skin_df['energy'] = energy\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zTV0mcJ7BHg"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlUBYRGD7BKR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, filters\n",
        "\n",
        "def calculate_edge_features(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Calculate the image gradient using the Sobel operator.\n",
        "    edge_sobel = filters.sobel(gray_image)\n",
        "\n",
        "    # Calculate the edge features.\n",
        "    edge_mean = np.mean(edge_sobel)\n",
        "    edge_std = np.std(edge_sobel)\n",
        "\n",
        "    # Return the features.\n",
        "    return edge_mean, edge_std\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the edge features in parallel.\n",
        "results = Parallel(n_jobs=-1)(delayed(calculate_edge_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "edge_mean, edge_std = zip(*results)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['edge_mean'] = edge_mean\n",
        "skin_df['edge_std'] = edge_std\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqH2SpXH7BNC"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNZuSXdk9WXe"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, measure, filters\n",
        "from skimage.segmentation import clear_border\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "def calculate_shape_features(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Apply a threshold to segment the lesion.\n",
        "    threshold = filters.threshold_otsu(gray_image)\n",
        "    binary_image = gray_image > threshold\n",
        "\n",
        "    # Clean up small objects in the binary image.\n",
        "    binary_image = clear_border(binary_image)\n",
        "    label_objects, _ = ndi.label(binary_image)\n",
        "    sizes = np.bincount(label_objects.ravel())\n",
        "    mask_sizes = sizes > 20\n",
        "    mask_sizes[0] = 0\n",
        "    clean_binary = mask_sizes[label_objects]\n",
        "\n",
        "    # Find the contours of the lesion.n\n",
        "    contours = measure.find_contours(clean_binary, 0.8)\n",
        "\n",
        "    # Ensure at least one contour has been found.\n",
        "    if len(contours) != 0:\n",
        "        # Choose the longest contour\n",
        "        contour = max(contours, key=len)\n",
        "\n",
        "        # Calculate the area and perimeter of the lesion.\n",
        "        area = cv2.contourArea(contour.astype(np.float32))\n",
        "        perimeter = cv2.arcLength(contour.astype(np.float32), True)\n",
        "\n",
        "        # Calculate the compactness and roundness of the lesion.\n",
        "        if perimeter == 0:\n",
        "            compactness = 0\n",
        "        else:\n",
        "            compactness = 4. * np.pi * (area / (perimeter * perimeter))\n",
        "\n",
        "        roundness = 4 * area / (np.pi * np.max(contour[:,0])**2)\n",
        "\n",
        "        # Return the features\n",
        "        return area, perimeter, compactness, roundness\n",
        "\n",
        "    # If no contour is found, return zeros.\n",
        "    else:\n",
        "        return 0, 0, 0, 0\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the shape features in parallel.\n",
        "results = Parallel(n_jobs=-1)(delayed(calculate_shape_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "area, perimeter, compactness, roundness = zip(*results)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['area'] = area\n",
        "skin_df['perimeter'] = perimeter\n",
        "skin_df['compactness'] = compactness\n",
        "skin_df['roundness'] = roundness\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkLD8Idd9Wa3"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWogO5j39We7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color\n",
        "\n",
        "def calculate_fft_features(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Calculate the Fourier Transform of the image.\n",
        "    # The fft2 function returns the two-dimensional Fourier Transform.\n",
        "    # And fftshift shifts the zero-frequency component to the center of the spectrum.\n",
        "\n",
        "    f = np.fft.fft2(gray_image)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "\n",
        "    # Calculate the magnitude of the Fourier spectrum, which is typically visualized.\n",
        "    # The log is used to reduce the dynamic range; otherwise, the low frequencies\n",
        "    # might dominate the visualization.\n",
        "    magnitude_spectrum = 20*np.log1p(np.abs(fshift))\n",
        "\n",
        "    # Calculate the features of the Fourier spectrum.\n",
        "    # In this case, we're calculating the mean and standard deviation.\n",
        "    fft_mean = np.mean(magnitude_spectrum)\n",
        "    fft_std = np.std(magnitude_spectrum)\n",
        "\n",
        "    # Return the features.\n",
        "    return fft_mean, fft_std\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the Fourier features in parallel.\n",
        "results = Parallel(n_jobs=-1)(delayed(calculate_fft_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "fft_mean, fft_std = zip(*results)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['fft_mean'] = fft_mean\n",
        "skin_df['fft_std'] = fft_std\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zAbu7wu9Wim"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, filters\n",
        "\n",
        "def calculate_density(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Determine a threshold for the image.\n",
        "    threshold = filters.threshold_otsu(gray_image)\n",
        "\n",
        "    # Calculate the \"density\" as the proportion of pixels above the threshold.\n",
        "    density = np.sum(gray_image > threshold) / np.prod(gray_image.shape)\n",
        "\n",
        "    # Return the density.\n",
        "    return density\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the density in parallel.\n",
        "density = Parallel(n_jobs=-1)(delayed(calculate_density)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['density'] = density\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_iPYduH9WoM"
      },
      "outputs": [],
      "source": [
        "# Hu Moments\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, filters\n",
        "\n",
        "def calculate_hu_moments(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Determine a threshold for the image.\n",
        "    threshold = filters.threshold_otsu(gray_image)\n",
        "\n",
        "    # Binarize the image.\n",
        "    binary_image = gray_image > threshold\n",
        "\n",
        "    # Calculate the moments of the image.\n",
        "    moments = cv2.moments(binary_image.astype(np.uint8))\n",
        "\n",
        "    # Calculate the Hu moments from these moments.\n",
        "    hu_moments = cv2.HuMoments(moments)\n",
        "\n",
        "    # Return the features.\n",
        "    return hu_moments[:, 0]\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the Hu moments in parallel.\n",
        "hu_moments = Parallel(n_jobs=-1)(delayed(calculate_hu_moments)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "hu_moments = np.array(hu_moments)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "for i in range(hu_moments.shape[1]):\n",
        "    skin_df['hu_moment_' + str(i)] = hu_moments[:, i]\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlrzuhTU-m5T"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E28PuCWf-nA1"
      },
      "outputs": [],
      "source": [
        "# LAB Color Space Feature:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color\n",
        "\n",
        "def calculate_lab_features(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to the LAB color space.\n",
        "    lab_image = color.rgb2lab(image)\n",
        "\n",
        "    # Calculate the LAB color features as the average of each component.\n",
        "    lab_features = np.mean(lab_image, axis=(0, 1))\n",
        "\n",
        "    # Return the features.\n",
        "    return lab_features\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the LAB color features in parallel.\n",
        "lab_features = Parallel(n_jobs=-1)(delayed(calculate_lab_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Separate the results into different lists.\n",
        "lab_features = np.array(lab_features)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "for i in range(lab_features.shape[1]):\n",
        "    skin_df['lab_feature_' + str(i)] = lab_features[:, i]\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lGwnfwZ-nIM"
      },
      "outputs": [],
      "source": [
        "# Haralick Features\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, feature, filters\n",
        "\n",
        "def calculate_haralick_features(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Determine a threshold for the image.\n",
        "    threshold = filters.threshold_otsu(gray_image)\n",
        "\n",
        "    # Binarize the image.\n",
        "    binary_image = gray_image > threshold\n",
        "\n",
        "    # Calculate the Haralick features.\n",
        "    glcm = feature.greycomatrix(binary_image.astype(np.uint8), distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "    haralick_features = feature.greycoprops(glcm, 'contrast')\n",
        "\n",
        "    # Return the features.\n",
        "    return haralick_features[0]\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the Haralick features in parallel.\n",
        "haralick_features = Parallel(n_jobs=-1)(delayed(calculate_haralick_features)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "#Separate the results into different lists.\n",
        "haralick_features = np.array(haralick_features)\n",
        "\n",
        "# Add the results to the dataset.\n",
        "for i in range(haralick_features.shape[1]):\n",
        "    skin_df['haralick_feature_' + str(i)] = haralick_features[:, i]\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "skin_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TcOG1Qm9WsN"
      },
      "outputs": [],
      "source": [
        "# Eccentricity Features:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from skimage import io, color, measure, filters\n",
        "\n",
        "def calculate_eccentricity(row):\n",
        "    # Load the image.\n",
        "    image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/' + row['image_id'] + '.jpg'\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale.\n",
        "    gray_image = color.rgb2gray(image)\n",
        "\n",
        "    # Determine a threshold for the image.\n",
        "    threshold = filters.threshold_otsu(gray_image)\n",
        "\n",
        "    # Binarize the image.\n",
        "    binary_image = gray_image > threshold\n",
        "\n",
        "    # Label the regions of the image.\n",
        "    labeled_image = measure.label(binary_image)\n",
        "\n",
        "    # Calculate the properties of the regions.\n",
        "    regions = measure.regionprops(labeled_image)\n",
        "\n",
        "    # Select the largest region.\n",
        "    largest_region = max(regions, key=lambda region: region.area)\n",
        "\n",
        "    # Calculate the eccentricity of the largest region.\n",
        "    eccentricity = largest_region.eccentricity\n",
        "\n",
        "    # Return the eccentricity.\n",
        "    return eccentricity\n",
        "\n",
        "# Load the dataset.\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')\n",
        "\n",
        "# Calculate the eccentricity in parallel.\n",
        "eccentricities = Parallel(n_jobs=-1)(delayed(calculate_eccentricity)(row) for _, row in skin_df.iterrows())\n",
        "\n",
        "# Add the results to the dataset.\n",
        "skin_df['eccentricity'] = eccentricities\n",
        "\n",
        "# Save the updated dataset.\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv', index=False)\n",
        "skin_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4o2InAC40Fm"
      },
      "outputs": [],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ_u3XxyCji0"
      },
      "outputs": [],
      "source": [
        "skin_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hRuKEYeCj4B"
      },
      "outputs": [],
      "source": [
        "skin_df= pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/HAM10000_all.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCHv19BABFlh"
      },
      "outputs": [],
      "source": [
        "skin_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZEzMv3SCkuR"
      },
      "outputs": [],
      "source": [
        "features=skin_df.drop(columns=['dx','cell_type', 'cell_type_idx'],axis=1)\n",
        "target=skin_df['cell_type_idx']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0mNAOpI40i_"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrsm0s3bCRd1"
      },
      "outputs": [],
      "source": [
        "features.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JZRpB5fHVcO"
      },
      "outputs": [],
      "source": [
        "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234, stratify=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G4hNRe9Smr-"
      },
      "outputs": [],
      "source": [
        "x_train_o.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/x_train_o.csv', index=False)\n",
        "x_test_o.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/x_test_o.csv', index=False)\n",
        "y_train_o.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_train_o.csv', index=False)\n",
        "y_test_o.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_test_o.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr3PxmJYO1MV"
      },
      "outputs": [],
      "source": [
        "# Reconstruye los conjuntos de datos de entrenamiento y prueba\n",
        "train_df = pd.concat([x_train_o, y_train_o], axis=1)\n",
        "test_df = pd.concat([x_test_o, y_test_o], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8THZy_pS3bb"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/train_df_recons.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/test_df_recons.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDXxfvGh2vwB"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/train_df_recons.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/test_df_recons.csv')\n",
        "x_train_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/x_train_o.csv')\n",
        "x_test_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/x_test_o.csv')\n",
        "y_train_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_train_o.csv')\n",
        "y_test_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_test_o.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m-OXXMK4GWT"
      },
      "outputs": [],
      "source": [
        "y_train_o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlP6qAAfO1RE"
      },
      "outputs": [],
      "source": [
        "# Find the majority class in the training set.\n",
        "class_counts = y_train_o['cell_type_idx'].value_counts()\n",
        "majority_class = class_counts.idxmax()\n",
        "minority_classes = y_train_o['cell_type_idx'].unique()\n",
        "minority_classes = minority_classes[minority_classes != majority_class]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JaByp26O1Wd"
      },
      "outputs": [],
      "source": [
        "# Under-sample the majority class in the training set.\n",
        "image_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/resized/'\n",
        "\n",
        "# Create an image data generator.\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "# Create a directory to save the augmented images.\n",
        "augmented_path = '/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/augmented/'\n",
        "if not os.path.exists(augmented_path):\n",
        "    os.mkdir(augmented_path)\n",
        "\n",
        "majority_df = train_df[train_df['cell_type_idx'] == majority_class]\n",
        "majority_df = resample(majority_df, replace=False, n_samples=3000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvpvHJ6M5Ja5"
      },
      "outputs": [],
      "source": [
        "majority_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6wGxkWv5HL9"
      },
      "outputs": [],
      "source": [
        "# Over-sample the minority classes in the training set.\n",
        "minority_dfs = []\n",
        "for minority_class in minority_classes:\n",
        "    minority_df = train_df[train_df['cell_type_idx'] == minority_class]\n",
        "    minority_df = resample(minority_df, replace=True, n_samples=1800)\n",
        "    minority_dfs.append(minority_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvvFshaU9jGt"
      },
      "outputs": [],
      "source": [
        "minority_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUfTGGAP5QvT"
      },
      "outputs": [],
      "source": [
        "# Combine the under-sampled and over-sampled samples.\n",
        "balanced_train_df = pd.concat([majority_df] + minority_dfs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NH_wyVp5YOP"
      },
      "outputs": [],
      "source": [
        "balanced_train_df\n",
        "balanced_train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/balanced_train_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdofvL24BBa3"
      },
      "outputs": [],
      "source": [
        "balanced_train_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/balanced_train_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkaDMNY66Bcd"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\n",
        "balanced_train_df['cell_type_idx'].value_counts().plot(kind='bar', ax=ax1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UaqalyjCAe0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "balanced_train_df.to_csv('balanced_train_df.csv', index=False)\n",
        "files.download('balanced_train_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOJMG3JVBi9_"
      },
      "outputs": [],
      "source": [
        "# Merge with the original balanced_train_df to get the corresponding labels.\n",
        "augmented_train_df = balanced_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3KeoQtVFOsC"
      },
      "outputs": [],
      "source": [
        "augmented_train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/augmented_train_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jod_fall59P"
      },
      "outputs": [],
      "source": [
        "augmented_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvhMv4gcCMUQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "augmented_train_df.to_csv('augmented_train_df.csv', index=False)\n",
        "files.download('augmented_train_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlQfCXs4xdXk"
      },
      "outputs": [],
      "source": [
        "augmented_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSHHuUuXE_FR"
      },
      "outputs": [],
      "source": [
        "x_test_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/x_test_o.csv')\n",
        "y_test_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_test_o.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u67Id-9E0Q91"
      },
      "outputs": [],
      "source": [
        "augmented_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8mUydWjRlWZ"
      },
      "outputs": [],
      "source": [
        "def load_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "        else:\n",
        "            print(f'Failed to load image: {img_path}')\n",
        "    return np.array(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrvJYDQrXb36"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "x_train_balanced = load_images(augmented_train_df['path'].tolist())\n",
        "y_train_balanced = augmented_train_df['cell_type_idx'].tolist()  # Using 'cell_type_idx' as the label column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjSBd8Ul04kS"
      },
      "outputs": [],
      "source": [
        "# Load images for testing from x_test_o\n",
        "x_test = load_images(x_test_o['path'].tolist())\n",
        "y_test = y_test_o['cell_type_idx'].tolist()  # Similarmente para los datos de prueba\n",
        "\n",
        "# Calculate mean and standard deviation for training images\n",
        "x_train_mean = np.mean(x_train_balanced, axis=(0, 1, 2))\n",
        "x_train_std = np.std(x_train_balanced, axis=(0, 1, 2))\n",
        "\n",
        "# Normalize both training and testing images with the same mean and standard deviation\n",
        "x_train_balanced = (x_train_balanced - x_train_mean)/x_train_std\n",
        "x_test = (x_test - x_train_mean)/x_train_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L51K-zJkW23L"
      },
      "outputs": [],
      "source": [
        "augmented_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcSrKs_nMBFY"
      },
      "outputs": [],
      "source": [
        "augmented_train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/augmented_train_df.csv', index=False)\n",
        "balanced_train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/balanced_train_df.csv', index=False)\n",
        "train_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/train_df.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/test_df.csv', index=False)\n",
        "skin_df.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/skin_df.csv', index=False)\n",
        "y_test_o.to_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_test_o.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6PBL7hBpMsu"
      },
      "outputs": [],
      "source": [
        "augmented_train_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/augmented_train_df.csv')\n",
        "balanced_train_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/balanced_train_df.csv')\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/train_df.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/test_df.csv')\n",
        "skin_df = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/skin_df.csv')\n",
        "y_test_o = pd.read_csv('/content/drive/MyDrive/TFM Cancer AI/TFM/Datos cáncer piel/Exports/y_test_o.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFefHFT_a9dM"
      },
      "outputs": [],
      "source": [
        "balanced_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Dpvy2ap95fo"
      },
      "outputs": [],
      "source": [
        "# Perform one-hot encoding on the labels\n",
        "\n",
        "# Extract the target variable from the balanced training set\n",
        "y_train_balanced = augmented_train_df['cell_type_idx']\n",
        "\n",
        "# Perform one-hot encoding on the labels\n",
        "y_train = to_categorical(y_train_balanced, num_classes = 7)\n",
        "y_test = to_categorical(y_test_o, num_classes = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTN_zkm-HVmD"
      },
      "outputs": [],
      "source": [
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train_balanced, y_train, test_size=0.1, random_state=2, stratify=y_train_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "asOezXYjM6Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb_lZJByzPZ7"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for 'sex' and 'localization'.\n",
        "augmented_train_df = pd.get_dummies(augmented_train_df, columns=['sex', 'localization'])"
      ],
      "metadata": {
        "id": "QodlpW5iWfws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.get_dummies(test_df, columns=['sex', 'localization'])\n",
        "augmented_test_df = test_df\n",
        "augmented_test_df"
      ],
      "metadata": {
        "id": "4dg_-58bYVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    # Calculation of precision and recall\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "    # We calculate F1 score\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "9KozH8xoY5-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model 5 in the Thesis Document\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Metric F1 score\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "# Load the pretrained DenseNet169 model.\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "intermediate_layer_model = Model(inputs=densenet_model.input, outputs=densenet_model.get_layer('conv5_block32_concat').output)\n",
        "\n",
        "# Extract features using the intermediate layer.\n",
        "x_train_features = intermediate_layer_model.predict(x_train)\n",
        "x_validate_features = intermediate_layer_model.predict(x_validate)\n",
        "\n",
        "# Hybrid model architecture.\n",
        "input_images = Input(shape=x_train_features.shape[1:])\n",
        "flatten = Flatten()(input_images)\n",
        "dense1 = Dense(256, activation='relu')(flatten)\n",
        "bn1 = BatchNormalization()(dense1)\n",
        "dropout1 = Dropout(0.5)(bn1)\n",
        "dense2 = Dense(128, activation='relu')(dropout1)\n",
        "bn2 = BatchNormalization()(dense2)\n",
        "dropout2 = Dropout(0.5)(bn2)\n",
        "\n",
        "input_features = Input(shape=(augmented_train_df.drop(columns=['lesion_id', 'image_id', 'dataset', 'cell_type_idx', 'path', 'dx_type']).shape[1],))\n",
        "concat = concatenate([dropout2, input_features])\n",
        "dense3 = Dense(64, activation='relu')(concat)\n",
        "dropout3 = Dropout(0.5)(dense3)\n",
        "output = Dense(7, activation='softmax')(dropout3)\n",
        "\n",
        "densenet_hybrid_model = Model(inputs=[input_images, input_features], outputs=output)\n",
        "densenet_hybrid_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "features_all = augmented_train_df.drop(columns=['lesion_id', 'image_id', 'dataset', 'cell_type_idx', 'path', 'dx_type']).values\n",
        "features_train, features_validate = train_test_split(features_all, test_size=0.1, random_state=2, stratify=y_train_balanced)\n",
        "\n",
        "#Training.\n",
        "densenet_hybrid_model.fit(datagen.flow([x_train_features, features_train], y_train, batch_size=30),\n",
        "                          epochs=30,\n",
        "                          validation_data=([x_validate_features, features_validate], y_validate))\n",
        "\n",
        "# Evaluation and prediction.\n",
        "x_test_features = intermediate_layer_model.predict(x_test)\n",
        "y_pred = densenet_hybrid_model.predict([x_test_features, augmented_test_df.drop(columns=['lesion_id', 'image_id', 'dataset', 'cell_type_idx', 'path', 'dx_type']).values])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# F1-Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "xABS1qMbGhY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We verify the data dimensions\n",
        "print(\"x_train_balanced:\", x_train_balanced.shape)\n",
        "print(\"x_train_features:\", x_train_features.shape)\n",
        "print(\"features_train:\", features_train.shape)\n",
        "print(\"y_train_img:\", y_train_img.shape)\n",
        "\n",
        "print(\"\\nx_validate_images:\", x_validate_images.shape)\n",
        "print(\"x_validate_features:\", x_validate_features.shape)\n",
        "print(\"features_validate:\", features_validate.shape)\n",
        "print(\"y_validate_img:\", y_validate_img.shape)\n"
      ],
      "metadata": {
        "id": "mHkp_-Y9aWuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_train_df.columns)"
      ],
      "metadata": {
        "id": "zuTCENh_Vwz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train_df"
      ],
      "metadata": {
        "id": "ZsS9KWsbUrD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 4 of the Thesis Document. Without using any pre-trained model.\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from keras.regularizers import l2\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def create_model():\n",
        "    input_shape = (75, 100, 3)\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = 0.01\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same',\n",
        "                    input_shape=input_shape, kernel_regularizer=l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same',\n",
        "                    kernel_regularizer=l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='Same',\n",
        "                    kernel_regularizer=l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='Same',\n",
        "                    kernel_regularizer=l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.40))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# With data augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "epochs = 50\n",
        "batch_size = 20\n",
        "# Define 5-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "\n",
        "# Convert labels from categorical to integer for stratifiedKFold\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "cvscores = []\n",
        "for train, test in kfold.split(x_train, y_train_int):\n",
        "  # create model\n",
        "  model = create_model()  # Create model should return a new instance of your model\n",
        "\n",
        "  # data augmentation for current fold\n",
        "  datagen.fit(x_train[train])\n",
        "\n",
        "  # Fit the model with current fold\n",
        "  history = model.fit(datagen.flow(x_train[train], y_train[train], batch_size=batch_size),\n",
        "                                epochs=epochs, validation_data=(x_train[test], y_train[test]),\n",
        "                                verbose=1, steps_per_epoch=x_train[train].shape[0] // batch_size,\n",
        "                                callbacks=[learning_rate_reduction])\n",
        "\n",
        "  # evaluate the model with current fold\n",
        "  scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
        "  print(f\"{model.metrics_names[1]}: {[f'{i:.2f}%' for i in scores[1]*100]}\")\n",
        "  cvscores.append(scores[1] * 100)\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: f1 = %f  ;  loss_v = %f\" % (np.mean(accuracy_v), np.mean(loss_v)))\n",
        "print(\"Test: f1 = %f  ;  loss = %f\" % (np.mean(accuracy), np.mean(loss)))\n",
        "\n",
        "\n",
        "# Save the model\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: f1 = %s ; loss_v = %f\" % ([f'{i:.2f}%' for i in accuracy_v*100], loss_v))\n",
        "print(\"Test: f1 = %s ; loss = %f\" % ([f'{i:.2f}%' for i in accuracy*100], loss))"
      ],
      "metadata": {
        "id": "MD1IvIgB9TIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYsI18Hz4apU"
      },
      "source": [
        "In this code, the pretrained DenseNet169 model is first loaded and used to extract features from the training and validation images. Then, the features are flattened and a MLP (Multi-Layer Perceptron) model is used for classification. Finally, the model is trained and evaluated on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zfhc6eHzCyM"
      },
      "outputs": [],
      "source": [
        "import numpy as np ### Model 1 in the Thesis Document\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load pre-trained DenseNet169 model\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "# Extract features using the pretrained DenseNet169 model.\n",
        "x_train_features = densenet_model.predict(x_train)\n",
        "x_validate_features = densenet_model.predict(x_validate)\n",
        "\n",
        "# Flatten the feature data.\n",
        "x_train_flattened = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_validate_flattened = x_validate_features.reshape(x_validate_features.shape[0], -1)\n",
        "\n",
        "# Define the MLP (Multi-Layer Perceptron) model for classification.\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(x_train_flattened.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model using the F1-score metric.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=7)])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, validation_data=(x_validate_flattened, y_validate), epochs=12, batch_size=30)\n",
        "\n",
        "# Predict the labels for the test set.\n",
        "x_test_features = densenet_model.predict(x_test)\n",
        "x_test_flattened = x_test_features.reshape(x_test_features.shape[0], -1)\n",
        "y_pred = model.predict(x_test_flattened)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"F1-Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXssWK8bCJ5h"
      },
      "outputs": [],
      "source": [
        "print(x_train_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG0hUgNk5Qr1"
      },
      "outputs": [],
      "source": [
        "#IMPROVED: In this code, the pretrained DenseNet169 model is initially loaded and employed to extract features from the training and validation images.\n",
        "#Subsequently, the features are flattened, and an MLP (Multi-Layer Perceptron) model is applied for classification. Ultimately, the model is trained and assessed on the test set.\n",
        "#Model 2 in the Thesis Document\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the pretrained DenseNet169 model.\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "# Obtain the intermediate layer.\n",
        "intermediate_layer_model = Model(inputs=densenet_model.input, outputs=densenet_model.get_layer('conv5_block32_concat').output)\n",
        "\n",
        "# Extract features using the intermediate layer.\n",
        "x_train_features = intermediate_layer_model.predict(x_train)\n",
        "x_validate_features = intermediate_layer_model.predict(x_validate)\n",
        "\n",
        "# Define the MLP (Multi-Layer Perceptron) model for classification.\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=x_train_features.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model with the F1-score metric.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=[tfa.metrics.F1Score(num_classes=7)])\n",
        "\n",
        "# Data Augmentation.\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Fit the data generator to the training set.\n",
        "datagen.fit(x_train_features)\n",
        "\n",
        "# Train the model with data augmentation.\n",
        "model.fit(datagen.flow(x_train_features, y_train, batch_size=30),\n",
        "          validation_data=(x_validate_features, y_validate),\n",
        "          epochs=30)\n",
        "\n",
        "# Predict labels for the test set.\n",
        "x_test_features = intermediate_layer_model.predict(x_test)\n",
        "y_pred = model.predict(x_test_features)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate the F1-score.\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"F1-Score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3AfNgp8W2Tr"
      },
      "outputs": [],
      "source": [
        "# Model 3 in the Thesis document. Using Densenet pre-trained model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Load the pretrained DenseNet169 model.\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "def create_model():\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = 0.01\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(densenet_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set a learning rate annealer.\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# Use data augmentation to prevent overfitting.\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "epochs = 50\n",
        "batch_size = 20\n",
        "# Define 5-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "\n",
        "# Convert labels from categorical to integer for stratifiedKFold\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "cvscores = []\n",
        "for train, test in kfold.split(x_train, y_train_int):\n",
        "  # create model\n",
        "  model = create_model()  # Create model should return a new instance of your model\n",
        "\n",
        "  # data augmentation for current fold\n",
        "  datagen.fit(x_train[train])\n",
        "\n",
        "  # Fit the model with current fold\n",
        "  history = model.fit(datagen.flow(x_train[train], y_train[train], batch_size=batch_size),\n",
        "                                epochs=epochs, validation_data=(x_train[test], y_train[test]),\n",
        "                                verbose=1, steps_per_epoch=x_train[train].shape[0] // batch_size,\n",
        "                                callbacks=[learning_rate_reduction])\n",
        "\n",
        "  # evaluate the model with current fold\n",
        "  scores = model.evaluate(x_train[test], y_train[test], verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We evaluate in the test subset\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"Test loss: {test_scores[0]}\")\n",
        "print(f\"Test F1-score: {test_scores[1]}\")"
      ],
      "metadata": {
        "id": "SZvxUjh96qoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 6 in the Thesis Document = Model 3+ using extra features\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 20\n",
        "\n",
        "# Load the pretrained DenseNet169 model.\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "# Extract features using the pretrained DenseNet169 model.\n",
        "intermediate_layer_model = Model(inputs=densenet_model.input, outputs=densenet_model.get_layer('conv5_block32_concat').output)\n",
        "\n",
        "# Obtain the training and validation features.\n",
        "x_train_features = intermediate_layer_model.predict(x_train)\n",
        "\n",
        "# Hybrid model architecture.\n",
        "\n",
        "# Image portion.\n",
        "input_images = Input(shape=x_train_features.shape[1:])\n",
        "flatten = Flatten()(input_images)\n",
        "dense_img = Dense(128, activation='relu')(flatten)\n",
        "bn_img = BatchNormalization()(dense_img)\n",
        "dropout_img = Dropout(0.5)(bn_img)\n",
        "\n",
        "# Additional features portion.\n",
        "input_features = Input(shape=(augmented_train_df.drop(columns=['lesion_id', 'image_id', 'dataset', 'cell_type_idx', 'path', 'dx_type']).shape[1],))\n",
        "\n",
        "# Concatenation.\n",
        "concat = concatenate([dropout_img, input_features])\n",
        "dense_concat = Dense(64, activation='relu')(concat)\n",
        "dropout_concat = Dropout(0.5)(dense_concat)\n",
        "output = Dense(7, activation='softmax')(dropout_concat)\n",
        "\n",
        "# Create the model.\n",
        "hybrid_model = Model(inputs=[input_images, input_features], outputs=output)\n",
        "hybrid_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=7)])\n",
        "\n",
        "# Data Augmentation (the same one you provided).\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "features_all = augmented_train_df.drop(columns=['lesion_id', 'image_id', 'dataset', 'cell_type_idx', 'path', 'dx_type']).values\n",
        "features_train, features_validate = train_test_split(features_all, test_size=0.1, random_state=2, stratify=y_train_balanced)\n",
        "\n",
        "# Initialize KFold.\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Training with KFold.\n",
        "for train, test in kfold.split(x_train, y_train_int):\n",
        "\n",
        "    # Data augmentation for the current fold.\n",
        "    datagen.fit(x_train[train])\n",
        "\n",
        "    history = hybrid_model.fit(datagen.flow([x_train_features[train], features_train[train]], y_train[train], batch_size=batch_size),\n",
        "                               epochs=epochs, validation_data=([x_train_features[test], features_train[test]], y_train[test]),\n",
        "                               verbose=1, steps_per_epoch=x_train[train].shape[0] // batch_size,\n",
        "                               callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=0.00001)])\n",
        "\n",
        "    scores = hybrid_model.evaluate([x_train_features[test], features_train[test]], y_train[test], verbose=0)\n",
        "\n",
        "# Evaluate on the test set.\n",
        "test_scores = hybrid_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"Test loss: {test_scores[0]}\")\n",
        "print(f\"Test F1-score: {test_scores[1]}\")"
      ],
      "metadata": {
        "id": "g741TwGwHMzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = hybrid_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"Test loss: {test_scores[0]}\")\n",
        "print(f\"Test F1-score: {test_scores[1]}\")\n"
      ],
      "metadata": {
        "id": "eDSO1u0oAdUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, BatchNormalization, Dropout, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Load the pre-trained DenseNet169 model\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "input_images = Input(shape=(75, 100, 3))\n",
        "densenet_features = densenet_model(input_images)\n",
        "flatten_features = Flatten()(densenet_features)\n",
        "\n",
        "# Additional features\n",
        "input_features = Input(shape=(extra_feature_shape,))\n",
        "concatenated_features = concatenate([flatten_features, input_features])\n",
        "\n",
        "# Build the hybrid model\n",
        "num_classes = 7\n",
        "l2_reg_rate = 0.01\n",
        "\n",
        "dense1 = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate))(concatenated_features)\n",
        "bn1 = BatchNormalization()(dense1)\n",
        "dropout1 = Dropout(0.5)(bn1)\n",
        "output = Dense(num_classes, activation='softmax')(dropout1)\n",
        "\n",
        "hybrid_model = Model(inputs=[input_images, input_features], outputs=output)\n",
        "hybrid_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# With data augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 20\n",
        "\n",
        "# Define 3-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "\n",
        "cvscores = []\n",
        "for train, test in kfold.split(x_train, y_train_int):\n",
        "    # Create a new instance of the hybrid model\n",
        "    model = create_model()\n",
        "\n",
        "    # Data augmentation for the current fold\n",
        "    datagen.fit(x_train[train])\n",
        "\n",
        "    # Fit the model with the current fold\n",
        "    history = model.fit(\n",
        "        datagen.flow([x_train[train], features_train[train]], y_train[train], batch_size=batch_size),\n",
        "        epochs=epochs, validation_data=([x_train[test], features_train[test]], y_train[test]),\n",
        "        verbose=1, steps_per_epoch=x_train[train].shape[0] // batch_size,\n",
        "        callbacks=[learning_rate_reduction]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model with the current fold\n",
        "    scores = model.evaluate([x_train[test], features_train[test]], y_train[test], verbose=0)\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "# Calculate the mean and standard deviation of F1 scores from cross-validation\n",
        "mean_f1_score = np.mean(cvscores)\n",
        "std_f1_score = np.std(cvscores)\n",
        "print(\"Mean F1-Score: {:.2f}%, Std F1-Score: {:.2f}%\".format(mean_f1_score, std_f1_score))\n"
      ],
      "metadata": {
        "id": "LvXxGTshHM-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# NOT USED DUE TO TAKING TOO LONG TO TRAIN. Using the pretrained Xception model and also using k-folds.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Definir el modelo base (Xception)\n",
        "def create_model():\n",
        "    base_model = Xception(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "    # Obtener la capa intermedia\n",
        "    intermediate_layer_model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "    # Definir el modelo MLP para clasificación\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(3, 3, 2048)))  # Ajusta la forma según la salida de Xception\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "    # Compilar el modelo con métrica de F1-score\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=[tfa.metrics.F1Score(num_classes=7)])\n",
        "\n",
        "    return intermediate_layer_model, model\n",
        "\n",
        "# Aumento de datos (Data Augmentation)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Implementación de k-folds\n",
        "n_splits = 3\n",
        "kf = KFold(n_splits=n_splits)\n",
        "fold = 1\n",
        "\n",
        "for train_idx, validate_idx in kf.split(x_train):\n",
        "    print(f\"Training on fold {fold}\")\n",
        "\n",
        "    x_train_fold = x_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    x_validate_fold = x_train[validate_idx]\n",
        "    y_validate_fold = y_train[validate_idx]\n",
        "\n",
        "    # Crear modelo y extraer características\n",
        "    intermediate_layer_model, model = create_model()\n",
        "    x_train_features = intermediate_layer_model.predict(x_train_fold)\n",
        "    x_validate_features = intermediate_layer_model.predict(x_validate_fold)\n",
        "\n",
        "    # Ajustar el generador de datos al conjunto de entrenamiento\n",
        "    datagen.fit(x_train_features)\n",
        "\n",
        "    # Entrenar el modelo con aumento de datos\n",
        "    model.fit(datagen.flow(x_train_features, y_train_fold, batch_size=500),\n",
        "              validation_data=(x_validate_features, y_validate_fold),\n",
        "              epochs=20)\n",
        "\n",
        "    fold += 1\n",
        "'''"
      ],
      "metadata": {
        "id": "Zn7giLasD_G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 5 in the Thesis Document. I removed k-folds because it takes too long to train.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the base model (Xception).\n",
        "def create_model():\n",
        "    base_model = Xception(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "    # Obtain the intermediate layer.\n",
        "    intermediate_layer_model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "    # Define the MLP model for classification.\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(3, 3, 2048)))  # Adjust the shape according to Xception's output.\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "    # Compile the model using the F1-score metric.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.5), metrics=[tfa.metrics.F1Score(num_classes=7)])\n",
        "\n",
        "    return intermediate_layer_model, model\n",
        "\n",
        "# Data Augmentation.\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Create the model and extract features.\n",
        "intermediate_layer_model, model = create_model()\n",
        "x_train_features = intermediate_layer_model.predict(x_train)\n",
        "\n",
        "# Fit the data generator to the training set.\n",
        "datagen.fit(x_train_features)\n",
        "\n",
        "# Train the model with data augmentation.\n",
        "model.fit(datagen.flow(x_train_features, y_train, batch_size=50),\n",
        "          epochs=20)\n"
      ],
      "metadata": {
        "id": "jWdW8vfMwT9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the test images through the intermediate model.\n",
        "x_test_features = intermediate_layer_model.predict(x_test)\n",
        "\n",
        "# Obtain predictions from the MLP model.\n",
        "predictions = model.predict(x_test_features)\n",
        "\n",
        "# Convert the predictions into labels.\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = np.sum(predicted_labels == true_labels) / len(true_labels)\n",
        "print(f\"Accuracy on test set: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "wTk7RQFZ1KcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqMhr-aegt8F"
      },
      "outputs": [],
      "source": [
        "'''#  Model 8. NOT USED DUE to time to train the model. Google Colab collapsed.\n",
        "\n",
        "efficientnet_model = EfficientNetB0(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "densenet_model = DenseNet169(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "resnet_model = ResNet152(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "inception_model = InceptionV3(include_top=False, input_shape=(75, 100, 3), weights='imagenet')\n",
        "\n",
        "def create_efficientnet_model(params):\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = params['l2_reg_rate']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(efficientnet_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_densenet_model(params):\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = params['l2_reg_rate']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(densenet_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_resnet_model(params):\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = params['l2_reg_rate']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(resnet_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_inception_model(params):\n",
        "    num_classes = 7\n",
        "    l2_reg_rate = params['l2_reg_rate']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(inception_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg_rate)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(num_classes=num_classes)])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# With data augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        rotation_range=30,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=1,\n",
        "        vertical_flip=1)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "hyperparams_grid = {\n",
        "    'l2_reg_rate': [0.01, 0.001],\n",
        "    'dropout_rate': [0.3, 0.4, 0.5]\n",
        "}\n",
        "\n",
        "# Define number of epochs, batch size, and kfolds\n",
        "epochs = 20\n",
        "batch_size = 15\n",
        "kfolds = 2\n",
        "\n",
        "# Convert labels from categorical to integer for stratifiedKFold\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Grid search for each model\n",
        "models = {\n",
        "    \"EfficientNet\": (create_efficientnet_model, efficientnet_model),\n",
        "    \"DenseNet\": (create_densenet_model, densenet_model),\n",
        "    \"ResNet\": (create_resnet_model, resnet_model),\n",
        "    \"InceptionNet\": (create_inception_model, inception_model)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, (create_model_func, model) in models.items():\n",
        "    best_score = 0\n",
        "    best_params = {}\n",
        "    best_model = None\n",
        "    for params in ParameterGrid(hyperparams_grid):\n",
        "        cvscores = []\n",
        "        kfold = StratifiedKFold(n_splits=kfolds, shuffle=True)\n",
        "        for train, test in kfold.split(x_train, y_train_int):\n",
        "            # create model\n",
        "            model = create_model_func(params)\n",
        "\n",
        "            # data augmentation for current fold\n",
        "            datagen.fit(x_train[train])\n",
        "\n",
        "            # Fit the model with current fold\n",
        "            history = model.fit(datagen.flow(x_train[train], y_train[train], batch_size=batch_size),\n",
        "                                epochs=epochs, validation_data=(x_train[test], y_train[test]),\n",
        "                                verbose=1, steps_per_epoch=x_train[train].shape[0] // batch_size,\n",
        "                                callbacks=[learning_rate_reduction])\n",
        "\n",
        "            # evaluate the model with current fold\n",
        "            scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
        "            cvscores.append(scores[1] * 100)\n",
        "\n",
        "        mean_score = np.mean(cvscores)\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = params\n",
        "            best_model = model\n",
        "\n",
        "    results[model_name] = {\n",
        "        'best_score': best_score,\n",
        "        'best_params': best_params\n",
        "    }\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.index.name = \"Model\"\n",
        "results_df.columns = ['Best Score', 'Best Params']\n",
        "\n",
        "# Print and save the results\n",
        "print(results_df)\n",
        "results_df.to_csv('grid_search_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYv16T-7FPxp"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXEY6DX8Tybd"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from contextlib import redirect_stdout\n",
        "from io import StringIO\n",
        "\n",
        "# Redirect the printed summary to a string buffer\n",
        "buffer = StringIO()\n",
        "with redirect_stdout(buffer):\n",
        "    model.summary()\n",
        "architecture_summary = buffer.getvalue().encode()\n",
        "\n",
        "# Convert the EagerTensor to a Python list\n",
        "data = [float(x) for x in np.array([2.0896919, 2.1128857, 2.1081853])]\n",
        "\n",
        "# Save the architecture and weights of the model\n",
        "with h5py.File(\"best_model_EfficientNet.h5\", \"w\") as file:\n",
        "    file.create_dataset(\"architecture\", data=np.array(architecture_summary))\n",
        "    file.create_dataset(\"data\", data=data)\n",
        "\n",
        "    # Save the weights as separate datasets\n",
        "    for i, weight in enumerate(model.get_weights()):\n",
        "        file.create_dataset(f\"weight_{i}\", data=weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zWtqYJeE3Un"
      },
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "model.save(\"best_model_EfficientNet.h5\")\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.index.name = \"Model\"\n",
        "results_df.columns = ['Best Score', 'Best Params']\n",
        "\n",
        "# Print and save the results\n",
        "print(results_df)\n",
        "results_df.to_csv('grid_search_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXPbOh6SugoH"
      },
      "outputs": [],
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: f1 = %f  ;  loss_v = %f\" % (np.mean(accuracy_v), np.mean(loss_v)))\n",
        "print(\"Test: f1 = %f  ;  loss = %f\" % (np.mean(accuracy), np.mean(loss)))\n",
        "# Save the model\n",
        "#model.save(\"model.h5\")\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: f1 = %s ; loss_v = %f\" % ([f'{i:.2f}%' for i in accuracy_v*100], loss_v))\n",
        "print(\"Test: f1 = %s ; loss = %f\" % ([f'{i:.2f}%' for i in accuracy*100], loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AFY8rl8Hp_z"
      },
      "outputs": [],
      "source": [
        "'''# Fit the model\n",
        "epochs = 5\n",
        "batch_size = 5\n",
        "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (x_validate,y_validate),\n",
        "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
        "                              , callbacks=[learning_rate_reduction])'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2aa53D9BBIk"
      },
      "outputs": [],
      "source": [
        "'''epochs = 50\n",
        "batch_size = 15\n",
        "\n",
        "# create model\n",
        "model = create_model()\n",
        "\n",
        "# data augmentation\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    epochs=epochs, validation_data=(x_validate, y_validate),\n",
        "                    verbose=1, steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    callbacks=[learning_rate_reduction])'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMIvDiK0EXHd"
      },
      "outputs": [],
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for f1 score\n",
        "    axs[0].plot(range(1,len(model_history.history['f1_score'])+1),model_history.history['f1_score'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_f1_score'])+1),model_history.history['val_f1_score'])\n",
        "    axs[0].set_title('Model F1 Score')\n",
        "    axs[0].set_ylabel('F1 Score')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['f1_score'])+1,len(model_history.history['f1_score']) // 10))\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1,len(model_history.history['loss']) // 10))\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "plot_model_history(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0oLh9U3IOmI"
      },
      "outputs": [],
      "source": [
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(x_validate)\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_validate,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
        "\n",
        "\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_M8dxG7IOsG"
      },
      "outputs": [],
      "source": [
        "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
        "plt.bar(np.arange(7),label_frac_error)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Fraction classified incorrectly')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}